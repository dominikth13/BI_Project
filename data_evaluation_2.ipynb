{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Evaluation\n",
    "\n",
    "- Ziel ist es, die erstellten Modelle auf Performance und Overfitting zu evaluieren\n",
    "- wir haben die Modelle DecisionTree, RandomForest, kNN Classifier und Categorical Naive Bayes Classifier aufgrund guter Ergebnisse in Laufzeit und Accuracy f체r eine genauere Analyse ausgew채hlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from confusion_matrix_utils import cross_val_predict, plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dec_tree = tree.DecisionTreeClassifier()\n",
    "ran_for = RandomForestClassifier(n_estimators = 70)\n",
    "kfold = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "cleaned_data = pd.read_csv('cleaned_data.csv')\n",
    "crime_cats_with_occs = cleaned_data[['CRIME_CAT','Crm.Cd']].groupby('CRIME_CAT')['Crm.Cd'].count().to_dict()\n",
    "sorted_labels = list(map(lambda x: x[0], sorted(list(crime_cats_with_occs.items()), key=lambda x: x[1], reverse=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LAT','LONG', 'RD']\n",
    "target = 'CRIME_CAT'\n",
    "selection = features + [target]\n",
    "\n",
    "predict_data_encoded = cleaned_data[selection].copy()\n",
    "#predict_data_encoded = pd.get_dummies(predict_data, columns=['AREA.NAME'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data_encoded.drop(target, axis=1), predict_data_encoded[target], test_size=0.2, random_state=42)\n",
    "ran_for.fit(X_train, y_train)\n",
    "\n",
    "print(f'Model Accuracy: {ran_for.score(X_test,y_test)}')\n",
    "max_tree_depths = [estimator.tree_.max_depth for estimator in ran_for.estimators_]\n",
    "max_depth = max(max_tree_depths)\n",
    "print(\"Maximale Tiefe aller Entscheidungsb채ume im Random Forest:\", max_depth)\n",
    "\n",
    "print(\"Anzahl der Entscheidungsb채ume im Random Forest:\", ran_for.n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting Graph Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(1, 40,1):\n",
    "    #dec_tree = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    ran_for = RandomForestClassifier(max_depth=i, n_estimators = 64)\n",
    "    score = cross_validate(ran_for, predict_data_encoded[features], predict_data_encoded[target], cv=5, return_train_score=True)\n",
    "    print(f\"Max Depth: {i}, Test Accuracy: {round(score['test_score'].mean(), ndigits=4)} ({round(score['test_score'].std(), ndigits=4)}), Train Accuracy: {round(score['train_score'].mean(), ndigits=4)} ({round(score['train_score'].std(), ndigits=4)})\")\n",
    "    acc.append((score['test_score'].mean(),score['test_score'].std(),score['train_score'].mean(),score['train_score'].std()))\n",
    "#print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "test_acc_list = list(map(lambda x: x[0], acc))[:30]\n",
    "test_std_list = list(map(lambda x: x[1], acc))[:30]\n",
    "train_acc_list = list(map(lambda x: x[2], acc))[:30]\n",
    "train_std_list = list(map(lambda x: x[3], acc))[:30]\n",
    "\n",
    "lower_bound_test = np.array(test_acc_list) - np.array(test_std_list)\n",
    "upper_bound_test = np.array(test_acc_list) + np.array(test_std_list)\n",
    "lower_bound_train = np.array(train_acc_list) - np.array(train_std_list)\n",
    "upper_bound_train = np.array(train_acc_list) + np.array(train_std_list)\n",
    "\n",
    "tree_depth = list(range(1,31, 1))\n",
    "N = len(tree_depth)\n",
    "tree_quantity = np.arange(N)\n",
    "plt.subplots(figsize=(10, 5))\n",
    "\n",
    "plt.plot(tree_quantity, test_acc_list, label=\"Holdout\", \n",
    "color=\"blue\")\n",
    "plt.fill_between(tree_quantity, lower_bound_test, upper_bound_test, color=\"deepskyblue\")\n",
    "\n",
    "\n",
    "plt.plot(tree_quantity, train_acc_list, label=\"Train\", \n",
    "color=\"orange\")\n",
    "plt.fill_between(tree_quantity, lower_bound_train, upper_bound_train, color=\"green\")\n",
    "\n",
    "\n",
    "plt.xticks(tree_quantity, tree_depth)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Baumtiefe\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title('Fitting Graph mit Cross Validation auf einem RandomForest', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lernkurve Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['RD','LAT','LONG']\n",
    "target = 'CRIME_CAT'\n",
    "selection = features + [target]\n",
    "\n",
    "predict_data_encoded = cleaned_data[selection].copy()\n",
    "#predict_data_encoded = pd.get_dummies(predict_data, columns=['AREA.NAME'])\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(predict_data_encoded.drop(target, axis=1), predict_data_encoded[target], test_size=0.2, random_state=42)\n",
    "#rand_for = RandomForestClassifier(max_depth= 30, n_estimators= 60)\n",
    "#score = cross_validate(rand_for, predict_data_encoded[features], predict_data_encoded[target], cv=5, return_train_score=True)\n",
    "#rand_for.fit(X_train,y_train)\n",
    "\n",
    "#print(f'Model Accuracy: {rand_for.score(X_test,y_test)}')\n",
    "#print(rand_for.get_depth()) \n",
    "\n",
    "test_sizes = list(np.flip(np.linspace(0.1,1,9,endpoint=False)))\n",
    "learning_curve = []\n",
    "for test_size in test_sizes:\n",
    "    model = RandomForestClassifier(max_depth= 30, n_estimators= 60)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predict_data_encoded[features], predict_data_encoded[target], test_size=test_size, random_state=42)\n",
    "    model.fit(X_train,y_train)\n",
    "    score = model.score(X_test,y_test)\n",
    "    learning_curve.append(score)\n",
    "    print(f'Score {test_size}: {score}')\n",
    "print(learning_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Build a Gaussian Classifier\n",
    "nb_class = RandomForestClassifier(max_depth=30 , n_estimators=60)\n",
    "\n",
    "features = ['LONG','LAT','RD']\n",
    "target = 'CRIME_CAT'\n",
    "selection = features + [target]\n",
    "predict_data_encoded = cleaned_data[selection].copy()\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "actual_classes, predict_classes, _ = cross_val_predict(DecisionTreeClassifier(max_depth = 25), kfold, np.array(predict_data_encoded[features]), np.array(predict_data_encoded[target]))\n",
    "plot_confusion_matrix(actual_classes, predict_classes, sorted_labels, mode='relative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lernkurve Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['RD','LAT','LONG']\n",
    "target = 'CRIME_CAT'\n",
    "selection = features + [target]\n",
    "\n",
    "predict_data_encoded = cleaned_data[selection].copy()\n",
    "#predict_data_encoded = pd.get_dummies(predict_data, columns=['AREA.NAME'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data_encoded.drop(target, axis=1), predict_data_encoded[target], test_size=0.2, random_state=42)\n",
    "dec_tree = tree.DecisionTreeClassifier(max_depth= 25)\n",
    "score = cross_validate(dec_tree, predict_data_encoded[features], predict_data_encoded[target], cv=5, return_train_score=True)\n",
    "dec_tree.fit(X_train,y_train)\n",
    "\n",
    "print(f'Model Accuracy: {dec_tree.score(X_test,y_test)}')\n",
    "print(dec_tree.get_depth())\n",
    "\n",
    "test_sizes = list(np.flip(np.linspace(0.1,1,9,endpoint=False)))\n",
    "learning_curve = []\n",
    "for test_size in test_sizes:\n",
    "    model = dec_tree\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predict_data_encoded[features], predict_data_encoded[target], test_size=test_size, random_state=42)\n",
    "    model.fit(X_train,y_train)\n",
    "    score = model.score(X_test,y_test)\n",
    "    learning_curve.append(score)\n",
    "    print(f'Score {test_size}: {score}')\n",
    "print(learning_curve)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

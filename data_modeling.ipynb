{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e83d1f6",
   "metadata": {},
   "source": [
    "# Data Modeling\n",
    "Zuerst vorbereitete Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73806194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "cleaned_data = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f58495b0",
   "metadata": {},
   "source": [
    "#### Location aufteilen in Dummy Varibalen \n",
    "Die Spalten AREA.NAME und RD werden durch dummy-0-1-Variablen abgebildet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalte LOCATION wird zu mehrere 0,1 Variablen um diese im Suchbaum abzubilden \n",
    "\n",
    "# One-Hot Encoding für das String-Feature \"LOCATION\"\n",
    "area_names = list(map(lambda x: 'AREA.NAME_' + x, set(cleaned_data['AREA.NAME'].values)))\n",
    "encoded_data = pd.get_dummies(cleaned_data, columns=['AREA.NAME'])\n",
    "cleaned_data = pd.concat([encoded_data], axis=1)\n",
    "# Anzeigen des transformierten DataFrames\n",
    "print(area_names)\n",
    "cleaned_data['RD'] = cleaned_data['RD'].astype(str)\n",
    "\n",
    "# Definiere eine Funktion, um die letzten beiden Zeichen einer Zeichenkette zu entfernen\n",
    "def remove_last_two_chars(text):\n",
    "    return text[:-1]\n",
    "\n",
    "# Wende die Funktion auf die Spalte \"RD\" an und speichere das Ergebnis in einer neuen Spalte \"New_RD\"\n",
    "cleaned_data['New_RD'] = cleaned_data['RD'].apply(remove_last_two_chars)\n",
    "cleaned_data['New_RD'] = cleaned_data['New_RD'].astype(int)\n",
    "# Gib den aktualisierten DataFrame aus\n",
    "cleaned_data\n",
    "\n",
    "\n",
    "cleaned_data['New_RD'] = cleaned_data['New_RD'].astype(str)\n",
    "rd_nr = list(map(lambda x: 'New_RD_' + x, set(cleaned_data['New_RD'].values)))\n",
    "encoded_data = pd.get_dummies(cleaned_data, columns=['New_RD'])\n",
    "cleaned_data = pd.concat([encoded_data], axis=1)\n",
    "print(rd_nr)\n",
    "\n",
    "# Gib den aktualisierten DataFrame aus\n",
    "cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb267f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Annahme: Du hast bereits einen DataFrame mit den Spalten \"RD\" und \"LAT\" erstellt.\n",
    "# Du kannst deine Daten in den DataFrame \"df\" laden.\n",
    "\n",
    "# Definiere die benutzerdefinierte Aggregationsfunktion, um den Mittelwert von \"LAT\" und den entsprechenden Wert von \"RD\" zu erhalten\n",
    "\n",
    "# Konvertiere die Spalte \"RD\" in einen String-Datentyp\n",
    "#cleaned_data['RD'] = cleaned_data['RD'].astype(str)\n",
    "\n",
    "# Definiere eine Funktion, um die letzten beiden Zeichen einer Zeichenkette zu entfernen\n",
    "#def remove_last_two_chars(text):\n",
    " #   return text[:-0]\n",
    "\n",
    "# Wende die Funktion auf die Spalte \"RD\" an und speichere das Ergebnis in einer neuen Spalte \"New_RD\"\n",
    "#cleaned_data['RD'] = cleaned_data['RD'].apply(remove_last_two_chars)\n",
    "\n",
    "\n",
    "def custom_agg(series):\n",
    "    return pd.Series({\n",
    "        'LAT_mean': series['LAT'].mean(),\n",
    "        'LONG_mean': series['LONG'].mean(),\n",
    "        'RD_value': series.iloc[0]\n",
    "    })\n",
    "\n",
    "# Gruppiere den DataFrame nach der Spalte \"RD\" und wende die benutzerdefinierte Aggregationsfunktion an\n",
    "result = cleaned_data.groupby('RD')['LAT', 'LONG'].apply(custom_agg).reset_index()\n",
    "\n",
    "# Gib das Ergebnis aus\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407dc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('ergebnis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d13dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lade die CSV-Datei in einen DataFrame\n",
    "df = pd.read_csv('ergebnis.csv')\n",
    "\n",
    "# Wähle die gewünschten Spalten aus\n",
    "df_filtered1 = df[df['RD'].between(200, 299)]\n",
    "df_filtered2 = df[df['RD'].between(300, 399)]\n",
    "df_filtered3 = df[df['RD'].between(400, 499)]\n",
    "df_filtered4 = df[df['RD'].between(500, 599)]\n",
    "\n",
    "spalte1_1 = df_filtered1['LAT_mean']\n",
    "spalte2_1 = df_filtered1['LONG_mean']\n",
    "spalte1_2 = df_filtered2['LAT_mean']\n",
    "spalte2_2 = df_filtered2['LONG_mean']\n",
    "spalte1_3 = df_filtered3['LAT_mean']\n",
    "spalte2_3 = df_filtered3['LONG_mean']\n",
    "spalte1_4 = df_filtered4['LAT_mean']\n",
    "spalte2_4 = df_filtered4['LONG_mean']\n",
    "# Erstelle das Punktdiagramm\n",
    "\n",
    "plt.scatter(spalte1_1, spalte2_1, c='red', label='Bereich 300-399')\n",
    "plt.scatter(spalte1_2, spalte2_2, c='blue', label='Bereich 400-499')\n",
    "plt.scatter(spalte1_3, spalte2_3, c='green', label='Bereich 500-599')\n",
    "plt.scatter(spalte1_4, spalte2_4, c='grey', label='Bereich 600-699')\n",
    "\n",
    "plt.ylabel('Längengrad (LONG)')\n",
    "plt.xlabel('Breitengrad (LAT)')\n",
    "plt.title('RD aufgeteilt nach AREA')\n",
    "plt.legend()\n",
    "\n",
    "# Setze die Range der x- und y-Achse auf feste Werte\n",
    "x_range = (33.7, 34.4 )\n",
    "y_range = (-118.7, -118.1)\n",
    "plt.xlim(x_range)\n",
    "plt.ylim(y_range)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d19f33b",
   "metadata": {},
   "source": [
    "modelle\n",
    "xgboost\n",
    "multilayerperception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa41af1",
   "metadata": {},
   "source": [
    "## Getestete Modelle\n",
    "Im folgenden werden einige Modelle mit den getesteten Parametern gezeigt. Dabei wurden natürlich nicht nur die gezeigten Features getestet. Insgesamt wurden für den DecisionTree ale Features geprüft und auch das Verhältnis zu den zu klassifizierenden Klassen `CRIME_VIOLENT`, `Crm.Cd` und `CRIME_CAT`. Mehr dazu im Projektbericht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db09a1",
   "metadata": {},
   "source": [
    "#### DecisionTree 1/4\n",
    "- features = ['RD']\n",
    "- target = 'CRIME_VIOLENT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', \"LAT\", \"LONG\"]\n",
    "target = 'CRIME_VIOLENT'\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "model = DecisionTreeClassifier(max_depth = 8)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103bd2d7",
   "metadata": {},
   "source": [
    "#### DecisionTree 2/4\n",
    "- features = ['LAT','LONG', 'RD', 'TIME.OCC_hour_cos']\n",
    "- target = 'CRIME_CAT'\n",
    "\n",
    "performt schlechter als ohne  'TIME.OCC_hour_cos' - siehe DecisionTee 3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94976de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['LAT','LONG', 'RD', 'TIME.OCC_hour_cos']\n",
    "target = 'CRIME_CAT'\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "model = DecisionTreeClassifier(max_depth = 80)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dd44ab9",
   "metadata": {},
   "source": [
    "#### DecisionTree 3/4\n",
    "- features = [ 'RD',  'LAT', 'LONG']\n",
    "- target = 'CRIME_CAT'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea31043",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = [ 'RD',  'LAT', 'LONG']\n",
    "target = 'CRIME_CAT'\n",
    "\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "model = DecisionTreeClassifier(max_depth = 30)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f388f6c",
   "metadata": {},
   "source": [
    "#### DecisionTree 4/4\n",
    "- features = [ 'RD',  'LAT', 'LONG']\n",
    "- target = 'Crm.Cd'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ae64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', 'LAT', 'LONG']\n",
    "target = 'Crm.Cd'\n",
    "\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "model = DecisionTreeClassifier(max_depth = 40)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c206ae",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "459418a0",
   "metadata": {},
   "source": [
    "#### RandomForest 1/4\n",
    "- features = ['RD', 'LAT', 'LONG']\n",
    "- target = 'CRIME_VIOLENT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae92147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', 'LAT', 'LONG']\n",
    "target = 'CRIME_VIOLENT'\n",
    "\n",
    "# Remove all NaN values\n",
    "predict_data = predict_data[predict_data['LAT'].notnull() & predict_data['LONG'].notnull()].copy()\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "\n",
    "model = RandomForestClassifier(max_depth = 20, n_estimators=70)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells: \" , accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c3cb6",
   "metadata": {},
   "source": [
    "#### RandomForest 2/4\n",
    "- features = ['RD', 'LAT', 'LONG']\n",
    "- target = 'CRIME_CAT'\n",
    "\n",
    "Bisher bestes Ergebnis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c704b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', 'LAT', 'LONG']\n",
    "target = 'CRIME_CAT'\n",
    "\n",
    "# Remove all NaN values\n",
    "predict_data = predict_data[predict_data['LAT'].notnull() & predict_data['LONG'].notnull()].copy()\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "\n",
    "model = RandomForestClassifier(max_depth = 24, n_estimators=64)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells: \" , accuracy)\n",
    "#Genauigkeit des Modells: deep: 24n_est: 64 0.3148376642071581"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4db0c3f8",
   "metadata": {},
   "source": [
    "#### RandomForest 3/4\n",
    "- features = ['RD', 'LAT', 'LONG']\n",
    "- target = 'Crm.Cd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', 'LAT','LONG']\n",
    "target = 'Crm.Cd'\n",
    "\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(max_depth = 40, n_estimators= 64)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0e27f",
   "metadata": {},
   "source": [
    "#### RandomForest 4/4\n",
    "- features = ['RD', 'LAT', 'LONG', 'TIME.OCC_hour_cos']\n",
    "- target = 'Crm.Cd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', 'LAT', 'LONG', 'TIME.OCC_hour_cos']\n",
    "target = 'Crm.Cd'\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(max_depth = 80, n_estimators= 64)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b1f2b",
   "metadata": {},
   "source": [
    "## Sequentielles neuronales Netzwerk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "064022f6",
   "metadata": {},
   "source": [
    "####  Sequentielles neuronales Netzwerk 1/2\n",
    "- Dense-Schicht\n",
    "- target = 'CRIME_CAT'\n",
    "- features = 'AREA', 'RD', 'LAT', 'LONG',  'TIME.OCC_hour_cos', 'DATE.OCC_day_cos', 'DATE.OCC_month_cos' AND ALL FEATURES\n",
    "- viel Ausprobiert - wenig gutes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d34c13c8",
   "metadata": {},
   "source": [
    "####  Sequentielles neuronales Netzwerk 2/2\n",
    "- Dense-Schicht\n",
    "- tensorflow Module müssen hierfür installiert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Schritt 1: Daten laden und vorverarbeiten\n",
    "predict_data = cleaned_data.copy()\n",
    "target = 'Crm.Cd'\n",
    "\n",
    "features = ['RD', 'LONG', 'LAT', 'TIME.OCC_hour_cos']\n",
    "# Remove all NaN values\n",
    "predict_data = predict_data[predict_data['LAT'].notnull() & predict_data['LONG'].notnull()].copy()\n",
    "\n",
    "\n",
    "# Schritt 2: Daten in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Schritt 5: Neuronales Netzwerk erstellen\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(16, activation='tanh', input_shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(16, activation='tanh'))\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train_encoded, epochs=2, batch_size=20, validation_split=0.2)\n",
    "\n",
    "# Schritt 7: Vorhersagen treffen\n",
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "# Schritt 8: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells: \" + str(accuracy))\n",
    "\n",
    "#höher als 42,98 ist nicht möglich. Habe activation = \"tanh\" und \"relu\" ausprobiert, 2 und 3 Layers und 32, 64 und 128 Neuronen. 1, 2, 10 Epochs und batchsize = 2, 10, 20 \n",
    "#\"mean_squared_error\" funktioniert garnicht\n",
    "#optimizer='adam' gut, optimizer='SGD' gut,  optimizer='Adagrad' gut\n",
    "# okay. iwas ist komisch. mit 3 mal 2 Neuronen bekomme ich trd über 42%. Das ist komisch. - erklärbar: einteilung bei den Koordinaten macht, dass wir auf 42% kommen \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5881b18e",
   "metadata": {},
   "source": [
    "## Naive Bayes Klassifikatoren"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d44b381",
   "metadata": {},
   "source": [
    "#### Naive Bayes-Klassifikator (GaussianNB)\n",
    "- Target: CRIME_CAT\n",
    "- Features: ['UNIX.TIMESTAMP','AREA.NAME','LAT','LONG']\n",
    "- viel Ausprobiert - wenig gutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a85da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "predict_data = cleaned_data.copy()\n",
    "# Build a Gaussian Classifier\n",
    "nb_class = GaussianNB()\n",
    "# Prior-Verteilungen für jede Klasse definieren\n",
    "\n",
    "features = ['UNIX.TIMESTAMP','LAT','LONG']\n",
    "target = 'CRIME_CAT'\n",
    "selection = features + [target]\n",
    "\n",
    "predict_data = cleaned_data[selection].copy()\n",
    "# Filtern von null (muss nur für eines gemacht werden, da Koordinaten nie alleine vorkommen)\n",
    "predict_data = predict_data[predict_data['LONG'].notnull()]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data.drop(target, axis=1), predict_data[target], test_size=0.2, random_state=42)\n",
    "nb_class.fit(X_train,y_train)\n",
    "\n",
    "print(\"Model Accuracy:\")\n",
    "nb_class.score(X_test,y_test)\n",
    "#ohne Priors: 42,811\n",
    "#probiert Priors anzupassen. Komme auf Maximal 21% WK. lohnt nicht\n",
    "#priors = [0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0565] - 8,9%\n",
    "\n",
    "#Auch weitere Anpassungen brachten keine Verbesserung:\n",
    "#print(\"Accuracy (Standardized):\", accuracy_standardized)\n",
    "#print(\"Accuracy (Normalized):\", accuracy_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee2f2dc",
   "metadata": {},
   "source": [
    "#### Naive Bayes-Klassifikator (CategoricalNB)\n",
    "- Target: CRIME_CAT\n",
    "- Features: ['TIME.OCC_hour','DATE.OCC_weekday','DATE.OCC_day','DATE.OCC_month','DATE.OCC_year','RD','LOCATION.street']\n",
    "- deutlich besser als Gauß, kann auch Straßen verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9917e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "# Build a Categorical Classifier\n",
    "nb_class = CategoricalNB()\n",
    "\n",
    "features = ['TIME.OCC_hour','DATE.OCC_weekday','DATE.OCC_day','DATE.OCC_month','DATE.OCC_year','RD','LOCATION.street']\n",
    "target = 'CRIME_CAT'\n",
    "selection = features + [target]\n",
    "predict_data_encoded = cleaned_data[selection].copy()\n",
    "predict_data_encoded['LOCATION.street']= LabelEncoder().fit_transform(predict_data_encoded['LOCATION.street'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data_encoded.drop(target, axis=1), predict_data_encoded[target], test_size=0.2, random_state=42)\n",
    "nb_class.fit(X_train,y_train)\n",
    "\n",
    "print(f'Model Accuracy: {nb_class.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22801977",
   "metadata": {},
   "source": [
    "### LogisticRegression\n",
    "- dauert viel zu lange\n",
    "- nicht viel besser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8805daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "target = 'CRIME_CAT'\n",
    "#column_to_exclude = ['Date.Rptd', 'DR.NO', 'DATE.OCC', 'TIME.OCC', 'AREA', 'AREA.NAME', 'RD', 'Crm.Cd', 'CrmCd.Desc', 'Status', 'Status.Desc', 'LOCATION', 'Cross.Street', 'LAT', 'LONG', 'UNIX.TIMESTAMP', 'TIME.OCC_hour', 'DATE.OCC_day', 'DATE.OCC_weekday', 'DATE.OCC_month', 'DATE.OCC_year', 'CRIME_VIOLENT', 'CRIME_CAT', 'Cos_Uhrzeit', 'TIME.OCC_hour_cos', 'DATE.OCC_day_cos', 'DATE.OCC_month_cos']\n",
    "column_to_exclude = ['Date.Rptd', 'DR.NO', 'DATE.OCC', 'TIME.OCC', 'Crm.Cd', 'CrmCd.Desc', 'Status', 'Status.Desc', 'LOCATION.street', \n",
    "                     'Cross.Street.street', 'LOCATION.house_number', 'Cross.Street.house_number','UNIX.TIMESTAMP', 'TIME.OCC_hour', \n",
    "                     'DATE.OCC_day', 'DATE.OCC_weekday', 'DATE.OCC_month', 'DATE.OCC_year', 'CRIME_VIOLENT', 'CRIME_CAT']\n",
    "#Enthalten: 'AREA', 'RD', 'LAT', 'LONG',  'TIME.OCC_hour_cos', 'DATE.OCC_day_cos', 'DATE.OCC_month_cos'\n",
    "features = predict_data.drop([target] + column_to_exclude, axis=1).columns\n",
    "\n",
    "# Remove all NaN values\n",
    "predict_data = predict_data[predict_data['LAT'].notnull() & predict_data['LONG'].notnull()].copy()\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Logistische Regression initialisieren und trainieren\n",
    "model = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren (optional)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Genauigkeitswert des Modells: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976c822",
   "metadata": {},
   "source": [
    "#### k-NN\n",
    "- liefert durchaus gute Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006bbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "target = 'Crm.Cd'\n",
    "\n",
    "features = ['RD', 'LONG', 'LAT', 'TIME.OCC_hour_cos']\n",
    "\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "predict_data = predict_data[predict_data['LAT'].notnull() & predict_data['LONG'].notnull()].copy()\n",
    "\n",
    "\n",
    "################\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Schritt 2: Daten normalisieren\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Schritt 3: Feature Selection\n",
    "selector = SelectKBest(k=3)  # Wähle die 10 besten Merkmale\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Schritt 4: Parameter Grid für die Grid Search festlegen\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 6, 9, 12, 15],\n",
    "    'weights': ['distance', 'uniform'],\n",
    "    'metric': ['manhattan', 'euclidean']\n",
    "}\n",
    "\n",
    "\n",
    "# Schritt 5: Grid Search durchführen\n",
    "model = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Schritt 6: Beste Parameter und Genauigkeit ausgeben\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"Parameter: \", best_params)\n",
    "print(\"Genauigkeit: \", best_accuracy)\n",
    "\n",
    "# Schritt 7: Vorhersagen treffen und Genauigkeit auf Testdaten berechnen\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit auf Testdaten: \", accuracy)\n",
    "\n",
    "#Genauigkeit mit k = 5 und keine weiteren anpassungen: Genauigkeit des k-NN-Modells (k=5): 0.36051278991467706\n",
    "\n",
    "#######\n",
    "# ['RD', 'LONG', 'LAT',\n",
    "#Parameter:  {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n",
    "#Genauigkeit:  0.20129741286336844\n",
    "#Genauigkeit auf Testdaten:  0.20492888812114932\n",
    "\n",
    " #['RD', 'LONG', 'LAT',\n",
    "#Parameter:  {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
    "#Genauigkeit:  0.2084188904571302\n",
    "#Genauigkeit auf Testdaten:  0.211262739678701\n",
    "\n",
    "# ['RD', 'LONG', 'LAT', 'TIME.OCC_hour_cos']\n",
    "#Parameter:  {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
    "#Genauigkeit:  0.2041867226325723\n",
    "#Genauigkeit auf Testdaten:  0.21273104163067888\n",
    "\n",
    "#Parameter:  {'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'distance'}\n",
    "#Genauigkeit:  0.20759014324317202\n",
    "#Genauigkeit auf Testdaten:  0.21584861272199327\n",
    "\n",
    "#Parameter:  {'metric': 'manhattan', 'n_neighbors': 100, 'weights': 'distance'}\n",
    "#Genauigkeit:  0.22118223326671585\n",
    "#Genauigkeit auf Testdaten:  0.22800631739999505\n",
    "\n",
    "#Parameter:  {'metric': 'manhattan', 'n_neighbors': 150, 'weights': 'distance'}\n",
    "#Genauigkeit:  0.22325924510292322\n",
    "#Genauigkeit auf Testdaten:  0.22984889239855555\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8389967c",
   "metadata": {},
   "source": [
    "## Finale Auswahl\n",
    "\n",
    "- Modelle Decision Tree, Random Forest, Categorical Naive Bayes und kNN werden weiter betrachtet\n",
    "- SNN und Logistic Regression haben zu lange Laufzeiten, wobei Ergebnisse nicht wirklich besser waren"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

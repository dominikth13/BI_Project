{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e83d1f6",
   "metadata": {},
   "source": [
    "# Data Modeling\n",
    "Zuerst vorbereitete Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73806194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "cleaned_data = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "489a54ba",
   "metadata": {},
   "source": [
    "### Robert \n",
    "--Predict the category of crime that occurred given a certain time and location"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f58495b0",
   "metadata": {},
   "source": [
    "#### Location aufteilen in Dummy Varibalen \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b21cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Überprüfen, ob \"AREA.NAME\" in den Spalten von \"cleaned_data\" vorhanden ist\n",
    "if 'AREA.NAME' in cleaned_data.columns:\n",
    "    # Spalte LOCATION wird zu mehrere 0,1 Variablen um diese im Suchbaum abzubilden \n",
    "\n",
    "    # One-Hot Encoding für das String-Feature \"LOCATION\"\n",
    "    area_names = list(map(lambda x: 'AREA.NAME_' + x, set(cleaned_data['AREA.NAME'].values)))\n",
    "    encoded_data = pd.get_dummies(cleaned_data, columns=['AREA.NAME'])\n",
    "    cleaned_data = pd.concat([encoded_data], axis=1)\n",
    "    # Anzeigen des transformierten DataFrames\n",
    "    #print(area_names)\n",
    "    cleaned_data['RD'] = cleaned_data['RD'].astype(str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4b79c",
   "metadata": {},
   "source": [
    "## DecisionTee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8123b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe263142",
   "metadata": {},
   "source": [
    "#### DecisionTree 1/4\n",
    "- features = ['RD']\n",
    "- target = 'CRIME_VIOLENT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94976de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit des Modells: 0.7413855505926675\n"
     ]
    }
   ],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', \"LAT\", \"LONG\"]\n",
    "target = 'CRIME_VIOLENT'\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "model = DecisionTreeClassifier(max_depth = 8)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db09a1",
   "metadata": {},
   "source": [
    "#### DecisionTree 2/4\n",
    "- features = ['LAT','LONG', 'RD', 'TIME.OCC_hour_cos']\n",
    "- target = 'CRIME_CAT'\n",
    "\n",
    "performt schlechter als ohne  'TIME.OCC_hour_cos' - siehe DecisionTee 3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "569a3235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit des Modells: 0.27553899431598516\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['LAT','LONG', 'RD', 'TIME.OCC_hour_cos']\n",
    "target = 'CRIME_CAT'\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "model = DecisionTreeClassifier(max_depth = 80)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc48509",
   "metadata": {},
   "source": [
    "#### DecisionTree 3/4\n",
    "- features = [ 'RD',  'LAT', 'LONG']\n",
    "- target = 'CRIME_CAT'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7a9ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit des Modells: 0.30010117710929596\n"
     ]
    }
   ],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = [ 'RD',  'LAT', 'LONG']\n",
    "target = 'CRIME_CAT'\n",
    "\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "model = DecisionTreeClassifier(max_depth = 30)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dd44ab9",
   "metadata": {},
   "source": [
    "#### DecisionTree 4/4\n",
    "- features = [ 'RD',  'LAT', 'LONG']\n",
    "- target = 'Crm.Cd'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0c1b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit des Modells: 0.23439774942625174\n"
     ]
    }
   ],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', 'LAT', 'LONG']\n",
    "target = 'Crm.Cd'\n",
    "\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "model = DecisionTreeClassifier(max_depth = 40)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe6cc09",
   "metadata": {},
   "source": [
    "## RandomForest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a3c98f",
   "metadata": {},
   "source": [
    "#### RandomForest 1/4\n",
    "- features = ['RD', 'LAT', 'LONG']\n",
    "- target = 'CRIME_VIOLENT'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db3693f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit des Modells:  0.742862078325889\n"
     ]
    }
   ],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', 'LAT', 'LONG']\n",
    "target = 'CRIME_VIOLENT'\n",
    "\n",
    "# Remove all NaN values\n",
    "predict_data = predict_data[predict_data['LAT'].notnull() & predict_data['LONG'].notnull()].copy()\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "\n",
    "model = RandomForestClassifier(max_depth = 20, n_estimators=70)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells: \" , accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "459418a0",
   "metadata": {},
   "source": [
    "#### RandomForest 2/4\n",
    "- features = ['RD', 'LAT', 'LONG']\n",
    "- target = 'CRIME_CAT'\n",
    "\n",
    "Bisher bestes Ergebnis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae92147d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit des Modells:  0.3143729075668962\n"
     ]
    }
   ],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', 'LAT', 'LONG']\n",
    "target = 'CRIME_CAT'\n",
    "\n",
    "# Remove all NaN values\n",
    "predict_data = predict_data[predict_data['LAT'].notnull() & predict_data['LONG'].notnull()].copy()\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Modell erstellen und trainieren\n",
    "\n",
    "model = RandomForestClassifier(max_depth = 24, n_estimators=64)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells: \" , accuracy)\n",
    "#Genauigkeit des Modells: deep: 24n_est: 64 0.3148376642071581"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c3cb6",
   "metadata": {},
   "source": [
    "#### RandomForest 3/4\n",
    "- features = ['RD', 'LAT', 'LONG']\n",
    "- target = 'Crm.Cd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6989e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit des Modells: 0.23849007559492963\n"
     ]
    }
   ],
   "source": [
    "predict_data = cleaned_data.copy()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', 'LAT','LONG']\n",
    "target = 'Crm.Cd'\n",
    "\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(max_depth = 40, n_estimators= 64)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b56bd",
   "metadata": {},
   "source": [
    "#### RandomForest 4/4\n",
    "- features = ['RD', 'LAT', 'LONG', 'TIME.OCC_hour_cos']\n",
    "- target = 'Crm.Cd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c704b427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit des Modells: 0.1905913514136005\n"
     ]
    }
   ],
   "source": [
    "#Forrest\n",
    "\n",
    "predict_data = cleaned_data.copy()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "features = ['RD', 'LAT', 'LONG', 'TIME.OCC_hour_cos']\n",
    "target = 'Crm.Cd'\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(max_depth = 80, n_estimators= 64)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "064022f6",
   "metadata": {},
   "source": [
    "####  sequentielles neuronales Netzwerk verwendet.\n",
    "- Dense-Schicht\n",
    "- target = 'CRIME_CAT'\n",
    "- features = 'AREA', 'RD', 'LAT', 'LONG',  'TIME.OCC_hour_cos', 'DATE.OCC_day_cos', 'DATE.OCC_month_cos' AND ALL FEATURES\n",
    "- viel Ausprobiert - wenig gutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a10005b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Schritt 1: Daten laden und vorverarbeiten\n",
    "predict_data = cleaned_data.copy()\n",
    "target = 'Crm.Cd'\n",
    "\n",
    "features = ['RD', 'LONG', 'LAT', 'TIME.OCC_hour_cos']\n",
    "# Remove all NaN values\n",
    "predict_data = predict_data[predict_data['LAT'].notnull() & predict_data['LONG'].notnull()].copy()\n",
    "\n",
    "# Schritt 2: Daten in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 5: Neuronales Netzwerk erstellen\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(16, activation='tanh', input_shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(16, activation='tanh'))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train_encoded, epochs=2, batch_size=20, validation_split=0.2)\n",
    "\n",
    "# Schritt 7: Vorhersagen treffen\n",
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "# Schritt 8: Modell evaluieren\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit des Modells: \" + str(accuracy))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d44b381",
   "metadata": {},
   "source": [
    "#### Naive Bayes-Klassifikator (GaussianNB)\n",
    "- Target: CRIME_CAT\n",
    "- Features: ['UNIX.TIMESTAMP','AREA.NAME','LAT','LONG']\n",
    "- viel Ausprobiert - wenig gutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a85da41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17517212447252178"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "predict_data = cleaned_data.copy()\n",
    "# Build a Gaussian Classifier\n",
    "nb_class = GaussianNB()\n",
    "\n",
    "\n",
    "features = ['UNIX.TIMESTAMP','LAT','LONG']\n",
    "target = 'CRIME_CAT'\n",
    "selection = features + [target]\n",
    "\n",
    "predict_data = cleaned_data[selection].copy()\n",
    "# Filtern von null (muss nur für eines gemacht werden, da Koordinaten nie alleine vorkommen)\n",
    "predict_data = predict_data[predict_data['LONG'].notnull()]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data.drop(target, axis=1), predict_data[target], test_size=0.2, random_state=42)\n",
    "nb_class.fit(X_train,y_train)\n",
    "\n",
    "print(\"Model Accuracy:\")\n",
    "nb_class.score(X_test,y_test)\n",
    "\n",
    "#probiert Priors anzupassen. \n",
    "#priors = [0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0555, 0.0565] - 8,9%\n",
    "# nicht gut\n",
    "\n",
    "#Auch weitere Anpassungen brachten keine Verbesserung:\n",
    "#print(\"Accuracy (Standardized):\", accuracy_standardized)\n",
    "#print(\"Accuracy (Normalized):\", accuracy_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf1ab7",
   "metadata": {},
   "source": [
    "### Kagetorischer Naive Bayers (CategoricalNB)\n",
    "- features = ['TIME.OCC_hour','DATE.OCC_weekday','DATE.OCC_day','DATE.OCC_month','DATE.OCC_year','RD','LOCATION.street']\n",
    "- target = 'CRIME_CAT'\n",
    "- sehr viel besser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59b21f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.2877419407908266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "# Build a Gaussian Classifier\n",
    "nb_class = CategoricalNB()\n",
    "\n",
    "features = ['TIME.OCC_hour','DATE.OCC_weekday','DATE.OCC_day','DATE.OCC_month','DATE.OCC_year','RD','LOCATION.street']\n",
    "target = 'CRIME_CAT'\n",
    "selection = features + [target]\n",
    "predict_data_encoded = cleaned_data[selection].copy()\n",
    "predict_data_encoded['LOCATION.street']= LabelEncoder().fit_transform(predict_data_encoded['LOCATION.street'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data_encoded.drop(target, axis=1), predict_data_encoded[target], test_size=0.2, random_state=42)\n",
    "nb_class.fit(X_train,y_train)\n",
    "\n",
    "print(f'Model Accuracy: {nb_class.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22801977",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8805daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeitswert des Modells: 0.1883539389153485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "# Schritt 2: Merkmale und Zielvariable definieren\n",
    "target = 'CRIME_CAT'\n",
    "#column_to_exclude = ['Date.Rptd', 'DR.NO', 'DATE.OCC', 'TIME.OCC', 'AREA', 'AREA.NAME', 'RD', 'Crm.Cd', 'CrmCd.Desc', 'Status', 'Status.Desc', 'LOCATION', 'Cross.Street', 'LAT', 'LONG', 'UNIX.TIMESTAMP', 'TIME.OCC_hour', 'DATE.OCC_day', 'DATE.OCC_weekday', 'DATE.OCC_month', 'DATE.OCC_year', 'CRIME_VIOLENT', 'CRIME_CAT', 'Cos_Uhrzeit', 'TIME.OCC_hour_cos', 'DATE.OCC_day_cos', 'DATE.OCC_month_cos']\n",
    "column_to_exclude = ['Date.Rptd', 'DR.NO', 'DATE.OCC', 'TIME.OCC', 'Crm.Cd', 'CrmCd.Desc', 'Status', 'Status.Desc', 'LOCATION.street', \n",
    "                     'Cross.Street.street', 'LOCATION.house_number', 'Cross.Street.house_number','UNIX.TIMESTAMP', 'TIME.OCC_hour', \n",
    "                     'DATE.OCC_day', 'DATE.OCC_weekday', 'DATE.OCC_month', 'DATE.OCC_year', 'CRIME_VIOLENT', 'CRIME_CAT']\n",
    "#Enthalten: 'AREA', 'RD', 'LAT', 'LONG',  'TIME.OCC_hour_cos', 'DATE.OCC_day_cos', 'DATE.OCC_month_cos'\n",
    "features = predict_data.drop([target] + column_to_exclude, axis=1).columns\n",
    "\n",
    "# Remove all NaN values\n",
    "predict_data = predict_data[predict_data['LAT'].notnull() & predict_data['LONG'].notnull()].copy()\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Schritt 4: Logistische Regression initialisieren und trainieren\n",
    "model = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Schritt 5: Vorhersagen treffen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Schritt 6: Modell evaluieren (optional)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Genauigkeitswert des Modells: \" + str(accuracy))\n",
    "\n",
    "\n",
    "#Genauigkeitswert des Modells: 0.41406762757950544"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976c822",
   "metadata": {},
   "source": [
    "#### k-NN \n",
    "- target = 'Crm.Cd'\n",
    "\n",
    "- features = ['RD', 'LONG', 'LAT', 'TIME.OCC_hour_cos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "006bbbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter:  {'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "Genauigkeit:  0.2864261100322282\n",
      "Genauigkeit auf Testdaten:  0.29081427008530136\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predict_data = cleaned_data.copy()\n",
    "\n",
    "target = 'CRIME_CAT'\n",
    "\n",
    "features = ['RD', 'LONG', 'LAT']\n",
    "\n",
    "# Schritt 3: Datensatz in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(predict_data[features], predict_data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "predict_data = predict_data[predict_data['LAT'].notnull() & predict_data['LONG'].notnull()].copy()\n",
    "################\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Schritt 2: Daten normalisieren\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Schritt 3: Feature Selection\n",
    "selector = SelectKBest(k=3)  # Wähle die 10 besten Merkmale\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Schritt 4: Parameter Grid für die Grid Search festlegen\n",
    "param_grid = {\n",
    "    'n_neighbors': [15],\n",
    "    'weights': ['distance'],\n",
    "    'metric': ['manhattan']\n",
    "}\n",
    "\n",
    "\n",
    "# Schritt 5: Grid Search durchführen\n",
    "model = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Schritt 6: Beste Parameter und Genauigkeit ausgeben\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"Parameter: \", best_params)\n",
    "print(\"Genauigkeit: \", best_accuracy)\n",
    "\n",
    "# Schritt 7: Vorhersagen treffen und Genauigkeit auf Testdaten berechnen\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Genauigkeit auf Testdaten: \", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
